{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import xgboost as xgb\n",
    "import operator\n",
    "from collections import Counter\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/train.csv', sep=';')\n",
    "test = pd.read_csv('../data/test.csv', sep=';')\n",
    "\n",
    "# check null value existance\n",
    "print 'NaN in train set', np.sum(np.sum(train.isnull(), axis = 1) != 0)\n",
    "print 'NaN in test set', np.sum(np.sum(test.isnull(), axis = 1) != 0)\n",
    "\n",
    "# replace NaN values with median\n",
    "train.fillna(train.median(), inplace=True)\n",
    "test.fillna(test.median(), inplace=True)\n",
    "\n",
    "# check one more time null value existance\n",
    "print 'NaN in train set after removing', np.sum(np.sum(train.isnull(), axis = 1) != 0)\n",
    "print 'NaN in test set after removing', np.sum(np.sum(test.isnull(), axis = 1) != 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def onehotencoding(data, features='all'):\n",
    "    \n",
    "    #import necessary modules\n",
    "    from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    \n",
    "    #write only not categorical names to variable non_cat_columns\n",
    "    non_cat_columns_data = [col for col in data.columns if data[col].dtype != 'O']\n",
    "            \n",
    "    #save all labels\n",
    "    labels = []\n",
    "    \n",
    "    # do the others\n",
    "    for i in features:\n",
    "        enc_label = LabelEncoder()\n",
    "        data[i] = enc_label.fit_transform(data[i])\n",
    "        labels.append(enc_label.classes_)\n",
    "    \n",
    "    #transforming names to indexes\n",
    "    columns = list(data.columns)\n",
    "    features_columns = [columns.index(i) for i in features]\n",
    "    \n",
    "    #do OneHotEncoding\n",
    "    enc_onehot = OneHotEncoder(categorical_features=features_columns, dtype='float32')\n",
    "    data = enc_onehot.fit_transform(data)\n",
    "    \n",
    "    \n",
    "    # create a list of columns to help create a DF from np array \n",
    "    new_cols = [features[i] + '_' + str(j) for i in range(0,len(features)) for j in labels[i]]\n",
    "    \n",
    "    #extend existing column names list with new ones\n",
    "    new_cols.extend(non_cat_columns_data)\n",
    "    \n",
    "    # create new dataframe\n",
    "    #new_data = pd.DataFrame(new_data.toarray(),columns=new_cols)\n",
    "    \n",
    "    # for i in data.columns:\n",
    "    #    if i not in features:\n",
    "    #        new_data[i] = data[i]\n",
    "            \n",
    "            \n",
    "    return data, new_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#leave only two digits of postalcode\n",
    "train.codepostal = [str(i)[:2] for i in train.codepostal]\n",
    "codepostal = train.codepostal.astype('str')\n",
    "\n",
    "# prepare data for label encoding\n",
    "\n",
    "# first save target in a separate variable and drop index\n",
    "#y_train = train.prime_tot_ttc\n",
    "y = train.prime_tot_ttc #/ train.crm\n",
    "#crm = train.crm\n",
    "train.drop(['prime_tot_ttc', 'id', 'codepostal'], axis = 1, inplace=True)\n",
    "test_ids = test.id\n",
    "#test_crm = test.crm\n",
    "test.drop(['id', 'codepostal'], axis = 1, inplace=True)\n",
    "\n",
    "# stack train and test sets for label encoding\n",
    "data = pd.concat([train, test], axis=0).reset_index(drop=True)\n",
    "#tsne = pd.DataFrame(tsne, columns=['tsne1', 'tsne2'])\n",
    "#data = pd.concat([data, tsne], axis=1).reset_index(drop=True)\n",
    "\n",
    "#find categorical variables for encoding\n",
    "cat_features = [col for col in data.columns if data[col].dtype == 'O']\n",
    "\n",
    "#apply ohe function\n",
    "ohe_encoded_data, col_names = onehotencoding(data,cat_features)\n",
    "del(data)\n",
    "\n",
    "# devide back new data frame on train and test sets\n",
    "ohe_encoded_train = ohe_encoded_data.tocsr()[:300000]\n",
    "ohe_encoded_test = ohe_encoded_data.tocsr()[300000:]\n",
    "\n",
    "del(ohe_encoded_data)\n",
    "\n",
    "print 'train set shape is', ohe_encoded_train.shape\n",
    "print 'test set shape is', ohe_encoded_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#validation\n",
    "\n",
    "val = ['10', '90', '91', '92', '93', '94', '95', '97']\n",
    "train = [key for key in Counter(codepostal).keys() if key not in val]\n",
    "\n",
    "val_indexes = [i for i, item in enumerate(codepostal) if item in val]\n",
    "train_indexes = [i for i, item in enumerate(codepostal) if item in train]\n",
    "\n",
    "#devide on train and validation set\n",
    "\n",
    "ohe_encoded_val = ohe_encoded_train.tocsr()[val_indexes]\n",
    "ohe_encoded_train_train = ohe_encoded_train.tocsr()[train_indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# xgboost parameters\n",
    "#set params\n",
    "param = {}\n",
    "param['objective'] = 'reg:linear'\n",
    "param['max_depth'] = 5\n",
    "param['eta'] = .1\n",
    "param['colsample_bytree'] = .7\n",
    "param['subsample'] = .7\n",
    "plst = list(param.items()) #+ [('eval_metric', 'merror')]\n",
    "num_round = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create mape metric for xgboost\n",
    "# metric mape\n",
    "def mape(y_true, y_pred): \n",
    "\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "def xgb_mape(preds, df):\n",
    "    labels = df.get_label()\n",
    "    assert len(preds) == len(labels)\n",
    "    labels = np.array(labels)\n",
    "    preds = np.array(preds)\n",
    "    \n",
    "    return 'error', mape(labels, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#run xbgoost on the whole train set\n",
    "evals_result = {}\n",
    "xgb_train = xgb.DMatrix( ohe_encoded_train_train, label = y[train_indexes], feature_names=col_names)\n",
    "xgb_val = xgb.DMatrix( ohe_encoded_val, label = y[val_indexes], feature_names=col_names)\n",
    "evallist = [(xgb_train,'train'), (xgb_val, 'val')]\n",
    "bst = xgb.train( param, xgb_train, num_round, evallist, early_stopping_rounds = 50, \n",
    "                feval = xgb_mape, evals_result=evals_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "error_df = pd.DataFrame({'error': map(lambda x: float(x), evals_result['val']['error']), 'iter': range(1,len(evals_result['val']['error'])+1)})\n",
    "error_df.plot(x='iter', y='error', figsize=(20,20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# predict test\n",
    "xgb_test = xgb.DMatrix( ohe_encoded_test, feature_names=col_names)\n",
    "predicted_values = bst.predict(xgb_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#save predictions\n",
    "answers = pd.DataFrame({'COTIS': predicted_values, 'ID': test_ids})\n",
    "answers[['ID', 'COTIS']].to_csv('../submissions/submission.csv',sep=';',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
